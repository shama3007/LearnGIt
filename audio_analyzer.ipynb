{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbcb739-223a-4caa-9194-11abcfcfcc28",
   "metadata": {},
   "source": [
    "********** Annual Sales Strategy Meet **********\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c058ba-3c75-4596-866e-73e1d39fca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 150, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "\n",
    "class AudioAnalyzerGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Audio Analysis Tool\")\n",
    "        self.root.geometry(\"1000x800\")\n",
    "        \n",
    "        self.create_widgets()\n",
    "        self.setup_sample_data()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # File Input Section\n",
    "        input_frame = ttk.Frame(self.root)\n",
    "        input_frame.pack(pady=10, fill=tk.X)\n",
    "        \n",
    "        ttk.Label(input_frame, text=\"Audio File Path:\").pack(side=tk.LEFT, padx=5)\n",
    "        self.file_entry = ttk.Entry(input_frame, width=50)\n",
    "        self.file_entry.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Button(input_frame, text=\"Browse\", command=self.browse_file).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Button(input_frame, text=\"Process\", command=self.process_audio).pack(side=tk.LEFT)\n",
    "\n",
    "        # Results Display\n",
    "        results_frame = ttk.Frame(self.root)\n",
    "        results_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        # Transcription Section\n",
    "        ttk.Label(results_frame, text=\"Full Transcription:\").pack(anchor=tk.W)\n",
    "        self.transcription_text = ScrolledText(results_frame, height=10, wrap=tk.WORD)\n",
    "        self.transcription_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Summary Section\n",
    "        ttk.Label(results_frame, text=\"Summary:\").pack(anchor=tk.W, pady=(10,0))\n",
    "        self.summary_text = ScrolledText(results_frame, height=5, wrap=tk.WORD)\n",
    "        self.summary_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Metrics Section\n",
    "        ttk.Label(results_frame, text=\"Participation Metrics:\").pack(anchor=tk.W, pady=(10,0))\n",
    "        self.metrics_text = tk.Text(results_frame, height=10, wrap=tk.NONE)\n",
    "        self.metrics_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    def setup_sample_data(self):\n",
    "        # Initial placeholder data\n",
    "        self.sample_transcription = \"Transcription will appear here...\"\n",
    "        self.sample_summary = \"Summary will be generated automatically...\"\n",
    "        self.metrics_data = [\n",
    "            (\"Speaker 1\", \"0.00 min\", 0, \"Processing...\")\n",
    "        ]\n",
    "\n",
    "    def browse_file(self):\n",
    "        filepath = filedialog.askopenfilename(filetypes=[(\"Audio Files\", \"*.wav *.mp3 *.ogg\")])\n",
    "        self.file_entry.delete(0, tk.END)\n",
    "        self.file_entry.insert(0, filepath)\n",
    "\n",
    "    def process_audio(self):\n",
    "        filepath = self.file_entry.get()\n",
    "        \n",
    "        if not filepath:\n",
    "            messagebox.showerror(\"Error\", \"Please select an audio file\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Load and convert audio\n",
    "            audio = AudioSegment.from_file(filepath)\n",
    "            duration_sec = len(audio) / 1000  # Get duration in seconds\n",
    "            \n",
    "            # Convert to WAV for processing\n",
    "            wav_path = \"audio2.wav\"\n",
    "            audio.export(wav_path, format=\"wav\")\n",
    "            \n",
    "            # Transcribe audio\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.AudioFile(wav_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                transcription = recognizer.recognize_google(audio_data)\n",
    "            \n",
    "            # Generate summary using Hugging Face transformers\n",
    "            summary = self.summarize_text(transcription)\n",
    "            \n",
    "            # Calculate metrics for multiple speakers\n",
    "            # This is a simple heuristic: split the transcription into parts and assign to speakers\n",
    "            # In a real-world scenario, you would use speaker diarization here\n",
    "            parts = transcription.split('.')\n",
    "            num_speakers = 2  # Assume 2 speakers for this example\n",
    "            speaker_parts = [parts[i::num_speakers] for i in range(num_speakers)]\n",
    "            \n",
    "            self.sample_transcription = transcription\n",
    "            self.sample_summary = summary\n",
    "            self.metrics_data = []\n",
    "            \n",
    "            for i, speaker_part in enumerate(speaker_parts):\n",
    "                speaker_duration = (len(speaker_part) / len(parts)) * duration_sec / 60\n",
    "                contributions = len(speaker_part)\n",
    "                self.metrics_data.append((f\"Speaker {i+1}\", f\"{speaker_duration:.2f} min\", contributions, \"Full conversation\"))\n",
    "            \n",
    "            self.show_results()\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Processing Error\", str(e))\n",
    "\n",
    "    def summarize_text(self, text):\n",
    "        \"\"\"Summarize text using Hugging Face transformers.\"\"\"\n",
    "        summarizer = pipeline(\"summarization\")\n",
    "        summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "\n",
    "    def show_results(self):\n",
    "        # Clear previous content\n",
    "        self.transcription_text.delete(1.0, tk.END)\n",
    "        self.summary_text.delete(1.0, tk.END)\n",
    "        self.metrics_text.delete(1.0, tk.END)\n",
    "\n",
    "        # Insert new results\n",
    "        self.transcription_text.insert(tk.END, self.sample_transcription)\n",
    "        self.summary_text.insert(tk.END, self.sample_summary)\n",
    "        self.create_metrics_table()\n",
    "\n",
    "    def create_metrics_table(self):\n",
    "        headers = [\"Participant\", \"Duration\", \"Contributions\", \"Key Points\"]\n",
    "        col_widths = [15, 15, 15, 60]\n",
    "        \n",
    "        # Create table header\n",
    "        separator = \"+\".join([\"-\"*w for w in col_widths])\n",
    "        self.metrics_text.insert(tk.END, f\"+{separator}+\\n\")\n",
    "        self.metrics_text.insert(tk.END, \"|\".join([h.ljust(w) for h, w in zip(headers, col_widths)]) + \"\\n\")\n",
    "        self.metrics_text.insert(tk.END, f\"+{separator}+\\n\")\n",
    "\n",
    "        # Add data rows\n",
    "        for row in self.metrics_data:\n",
    "            formatted_row = \"|\".join([str(cell).ljust(w) for cell, w in zip(row, col_widths)])\n",
    "            self.metrics_text.insert(tk.END, f\"|{formatted_row}|\\n\")\n",
    "            self.metrics_text.insert(tk.END, f\"+{separator}+\\n\")\n",
    "\n",
    "        # Configure table styling\n",
    "        self.metrics_text.configure(font=(\"Courier New\", 10), state=tk.DISABLED)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AudioAnalyzerGUI(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e53f1-e507-4d2b-8366-c19bd1338725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b3fab-475f-4f06-846a-9d5d452e1e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
